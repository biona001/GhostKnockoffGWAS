{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer documentation\n",
    "\n",
    "This is for advanced users who wish to build customized knockoff analysis pipelines. Currently, customization is not easy, but it is possible in principle at 2 levels: \n",
    "\n",
    "1. Constructing knockoff statistics for custom LD panels, including\n",
    "    + Specifying which LD panel to use\n",
    "    + Defining quasi-independent regions and groups\n",
    "    + Solving the knockoff (convex) optimization problem\n",
    "    + Saving the result in a easy-to-read format, which will be read in step 2\n",
    "2. Ghost Knockoff sampling and high dimensional Lasso regression\n",
    "    + Read pre-computed knockoff statistics from step 1\n",
    "    + Sample Ghost Knockoffs\n",
    "    + Fit a pseudo-lasso problem\n",
    "    + Applying the knockoff filter\n",
    "\n",
    "If you would like assistance on any of these steps, feel free to reach out to us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing knockoff statistics for custom LD panels\n",
    "\n",
    "+ Processing of LD panels (including downloading and importing the data matrices) is carried out by [EasyLD.jl](https://github.com/biona001/EasyLD.jl). This package should make it easy to import a region of the LD matrix into memory in Julia.\n",
    "+ To partition the extremely large LD matrix into manageable pieces, we directly adopted the output of [ldetect](https://bitbucket.org/nygcresearch/ldetect-data/src/master/) for which `AFR` (african), `ASN` (east Asians), and `EUR` (european) results are already available (position coordinates are given in HG19). \n",
    "+ Knockoff optimization problem was carried out by [Knockoffs.jl](https://github.com/biona001/Knockoffs.jl).\n",
    "\n",
    "Because pre-computed knockoff statistics are available for download, users do not have to manually install EasyLD.jl nor Knockoffs.jl to carry out this step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ghost Knockoff sampling and high dimensional Lasso regression\n",
    "\n",
    "Over 1703 quasi-independent blocks, we have assembled\n",
    "\\begin{align*}\n",
    "    \\Sigma =\n",
    "    \\begin{bmatrix}\n",
    "        \\Sigma_1 & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & \\Sigma_{1703}\n",
    "    \\end{bmatrix}, \\quad\n",
    "    S = \n",
    "    \\begin{bmatrix}\n",
    "        S_1 & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & S_{1703}\n",
    "    \\end{bmatrix}, \\quad\n",
    "    S_i = \n",
    "    \\begin{bmatrix}\n",
    "        S_{i,1} & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & S_{i,G_i}\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "where $\\Sigma_i$ are LD matrices obtained from the Pan-UKBB panel and $S_i$ is the group-block-diagonal matrices obtained by solving the knockoff optimization problem. Given a Z-score vector $z$, we can compute $r = \\frac{1}{\\sqrt{n}} z$, and `ghostbasil` will solve the following optimization problem with $\\lambda \\ge 0, p_i \\ge 0$, and $0 \\le \\alpha \\le 1$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\min \\frac{1}{2}\\beta^t A \\beta - \\beta^tr + \\lambda\\sum_ip_i\\left(\\alpha|\\beta_i| + \\frac{1-\\alpha}{2}\\beta_i^2\\right)\n",
    "\\end{align*}\n",
    "\n",
    "In `GhostKnockoffGWAS`, we set $\\alpha = 1$ (i.e. a Lasso problem) and $p_i = 1$ for all $i$. $A = \\frac{1}{n}[X,\\tilde{X}]'[X,\\tilde{X}]$ and $\\beta$ contains the effect size for both original variables and their knockoffs. \n",
    "\n",
    "To solve this problem, we leverage the fact that Lasso's objective is seprable over the blocks: as long as we can find a lambda sequence to be used for all blocks, we can fit each block separately. Since the max lambda is only related to the marginal correlation between each feature and $y$, and the knockoffs are exchangeable to the original features, we can use the original genome-wide Z-scores to compute the lambda sequence. \n",
    "\n",
    "Thus, for each block $i \\in \\{1,...,1703\\}$, we will call `ghostbasil(Bi, r)` where\n",
    "\\begin{align*}\n",
    "    B_i &= \\text{BlockGroupGhostMatrix}(C_i, S_i, m+1)\\\\\n",
    "    C_i &= \\Sigma_i - S_i\n",
    "\\end{align*}  \n",
    "Note that, since we use representative variant approach, $S_i$ is generally a dense matrix. To input a dense matrix, we use Jame's function `BlockGroupGhostMatrix` with a single block. \n",
    "\\begin{align*}\n",
    "    B_i = \\text{BlockGroupGhostMatrix}(C_i, S_i, m+1) = \n",
    "    \\begin{bmatrix}\n",
    "        C_i+S_i & C_i & ... & C_i\\\\\n",
    "        C_i & C_i+S_i & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        C_i & C_i & & C_i + S_i\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "with the understanding that $B_i$ is the covariance matrix for $(Z, \\tilde{Z}_1,...,\\tilde{Z}_m)$\n",
    "\\begin{align*}\n",
    "    B_i = \n",
    "    \\begin{bmatrix}\n",
    "        \\Sigma_i & \\Sigma_i-S_i & ... & \\Sigma_i-S_i\\\\\n",
    "        \\Sigma_i-S_i & \\Sigma_i & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        \\Sigma_i-S_i & \\Sigma_i-S_i & & \\Sigma_i\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        C_i+S_i & C_i & ... & C_i\\\\\n",
    "        C_i & C_i+S_i & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        C_i & C_i & & C_i + S_i\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "where $C_i = \\Sigma_i - S_i$. In Julia, this functionality is supported via the [ghostbasil_jll](https://github.com/biona001/ghostbasil_jll.jl/tree/main) package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the binaries\n",
    "\n",
    "1. Make sure `gcc` is available. We recommend version 7.1, but [avoid using GCC 11+](https://github.com/JuliaPackaging/Yggdrasil/blob/0d38df8bc8ad10cff5fba1c19a5932a84286fcd2/CONTRIBUTING.md#compatibility-tips).\n",
    "2. Make sure `GhostKnockoffGWAS` is installed within Julia. \n",
    "3. `dev` the package via\n",
    "```julia\n",
    "]dev GhostKnockoffGWAS\n",
    "```\n",
    "4. compile using [PackageCompiler.jl](https://github.com/JuliaLang/PackageCompiler.jl)\n",
    "```julia\n",
    "using PackageCompiler, GhostKnockoffGWAS\n",
    "src = normpath(pathof(GhostKnockoffGWAS), \"../..\")\n",
    "des = normpath(pathof(GhostKnockoffGWAS), \"../../app_linux_x86\")\n",
    "precompile_script = normpath(pathof(GhostKnockoffGWAS), \"../precompile.jl\")\n",
    "@time create_app(src, des, \n",
    "    include_lazy_artifacts=true, \n",
    "    force=true, \n",
    "    precompile_execution_file=precompile_script\n",
    ")\n",
    "```\n",
    "The last step takes 1-2 hours. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
